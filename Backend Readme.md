# ğŸ¤– Multimodal AI Assistant - Complete Backend System

[![Node.js](https://img.shields.io/badge/Node.js-18+-green.svg)](https://nodejs.org/)
[![MongoDB](https://img.shields.io/badge/MongoDB-Atlas-green.svg)](https://www.mongodb.com/atlas)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4-blue.svg)](https://openai.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://docker.com/)
[![Flutter](https://img.shields.io/badge/Flutter-Optimized-blue.svg)](https://flutter.dev/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

A **production-ready**, **enterprise-grade** Node.js backend system specifically designed for Flutter multimodal AI applications. This comprehensive backend provides authentication, AI services, video processing, embeddings, and user management with MongoDB Atlas integration.

## ğŸŒŸ **System Overview**

This backend powers modern AI-driven mobile applications with:
- **ğŸ” Complete Authentication System** - JWT + OAuth with session management
- **ğŸ¤– Advanced AI Services** - Chat, Vision, Speech, Text-to-Speech, Embeddings
- **ğŸ¥ Video Processing Pipeline** - Upload, frame extraction, thumbnail generation
- **ğŸ“Š User Management** - Profiles, quotas, analytics, usage tracking
- **ğŸš€ Production Ready** - Docker, MongoDB Atlas, comprehensive monitoring
- **ğŸ“± Flutter Optimized** - Mobile-first API design with proper error handling

## ğŸ—ï¸ **System Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Flutter App   â”‚â—„â”€â”€â–ºâ”‚   Backend API    â”‚â—„â”€â”€â–ºâ”‚  MongoDB Atlas  â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Authenticationâ”‚    â”‚ â€¢ JWT Auth       â”‚    â”‚ â€¢ User Data     â”‚
â”‚ â€¢ AI Chat       â”‚    â”‚ â€¢ AI Services    â”‚    â”‚ â€¢ AI Jobs       â”‚
â”‚ â€¢ Video Upload  â”‚    â”‚ â€¢ Video Process  â”‚    â”‚ â€¢ Embeddings    â”‚
â”‚ â€¢ File Managementâ”‚   â”‚ â€¢ Rate Limiting  â”‚    â”‚ â€¢ Video Jobs    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚   External APIs â”‚
                       â”‚                 â”‚
                       â”‚ â€¢ OpenAI GPT-4  â”‚
                       â”‚ â€¢ Whisper STT   â”‚
                       â”‚ â€¢ DALL-E Vision â”‚
                       â”‚ â€¢ TTS Synthesis â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ **Core Features**

### ğŸ” **Enterprise Authentication System**
- **JWT Authentication** - Secure token-based auth with refresh tokens
- **OAuth Integration** - Google social login
- **Session Management** - Multi-device session tracking and control
- **Rate Limiting** - Advanced protection against abuse
- **Quota Management** - Usage tracking and limits per user
- **Security Headers** - Helmet.js protection with CORS

### ğŸ¤– **Advanced AI Services**
- **ğŸ’¬ Chat Completion** - GPT-4 powered conversations with context memory
- **ğŸ¤ Speech-to-Text** - Whisper integration for high-accuracy transcription
- **ğŸ”Š Text-to-Speech** - Premium voice synthesis with multiple voices
- **ğŸ‘ï¸ Computer Vision** - Image analysis and description with GPT-4 Vision
- **ğŸ§  Embeddings** - Semantic search and similarity matching
- **ğŸ“Š Job Tracking** - Complete AI operation history and analytics

### ğŸ¥ **Professional Video Processing**
- **ğŸ“¤ Smart Upload** - Multi-format video support with validation
- **ğŸ–¼ï¸ Frame Extraction** - Customizable interval frame extraction
- **ğŸ–¼ï¸ Thumbnail Generation** - Automatic video thumbnail creation
- **âš¡ FFmpeg Integration** - Professional video processing pipeline
- **ğŸ“ Format Validation** - Size, duration, and format restrictions
- **ğŸ—‚ï¸ Asset Management** - Organized file storage and cleanup

### ğŸ‘¤ **Comprehensive User Management**
- **ğŸ‘¤ Profile System** - Complete user profiles with avatar upload
- **ğŸ“Š Usage Analytics** - Detailed usage statistics and insights
- **ğŸ’³ Quota Tracking** - Real-time usage monitoring and limits
- **ğŸ”§ Account Controls** - Profile updates, password changes, deactivation
- **ğŸ“± Session Management** - View and revoke active sessions
- **ğŸ“ˆ Performance Metrics** - User engagement and API usage analytics

## âš¡ **Quick Start Guide**

### ğŸ“‹ **Prerequisites**
- **Node.js 18+** - [Download](https://nodejs.org/)
- **MongoDB Atlas Account** - [Free Signup](https://www.mongodb.com/atlas) (Recommended)
- **OpenAI API Key** - [Get API Key](https://platform.openai.com/api-keys)
- **Docker & Docker Compose** - [Install Docker](https://docs.docker.com/get-docker/)
- **FFmpeg** - For video processing (included in Docker)

### ğŸ¯ **5-Minute Setup**

#### **Step 1: Clone & Setup** (1 minute)
```bash
# Clone the repository
git clone https://github.com/your-username/multimodal-ai-assistant.git
cd multimodal-ai-assistant

# Install dependencies
npm install

# Setup environment
cp .env.example .env
```

#### **Step 2: Configure MongoDB Atlas** (2 minutes)
1. **Create Account**: [MongoDB Atlas](https://www.mongodb.com/atlas) â†’ Sign up free
2. **Create Cluster**: Choose M0 (Free) â†’ Select region â†’ Create
3. **Database User**: Add user with read/write permissions
4. **Network Access**: Add IP `0.0.0.0/0` (development) or your specific IP
5. **Get Connection String**: Connect â†’ Application â†’ Copy connection string

#### **Step 3: Environment Configuration** (1 minute)
Edit `.env` file with your credentials:
```env
# ğŸ—„ï¸ Database (MongoDB Atlas)
MONGODB_URI=mongodb+srv://username:password@cluster.mongodb.net/multimodal-ai-assistant?retryWrites=true&w=majority

# ğŸ”‘ Authentication
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production

# ğŸ¤– OpenAI API (Required)
OPENAI_API_KEY=sk-your-openai-api-key

# ğŸ” OAuth (Optional - for Google login)
GOOGLE_CLIENT_ID=your-google-client-id.apps.googleusercontent.com
GOOGLE_CLIENT_SECRET=your-google-client-secret

# âš™ï¸ App Configuration
APP_NAME=Multimodal AI Assistant
APP_ENVIRONMENT=development
DEBUG_MODE=true
PORT=3000
```

#### **Step 4: Launch Backend** (1 minute)

**ğŸŒŸ Option A: MongoDB Atlas (Recommended)**
```bash
# Start with MongoDB Atlas (no local database needed)
docker-compose -f docker-compose.atlas.yml up -d

# Check status
docker-compose -f docker-compose.atlas.yml ps

# View logs
docker-compose -f docker-compose.atlas.yml logs -f app
```

**ğŸ”§ Option B: Local Development**
```bash
# For development with hot reload
npm run dev

# Or with local MongoDB
docker-compose up -d
```

#### **Step 5: Verify Setup** (30 seconds)
```bash
# Health check
curl http://localhost:3000/health

# Expected response:
{
  "status": "OK",
  "timestamp": "2024-01-01T00:00:00.000Z",
  "version": "1.0.0",
  "environment": "production"
}
```

### ğŸ‰ **You're Ready!**
- **ğŸŒ API Base URL**: `http://localhost:3000/api`
- **ğŸ“š API Documentation**: `http://localhost:3000/api-docs`
- **â¤ï¸ Health Check**: `http://localhost:3000/health`

## ğŸ—„ï¸ **Database Architecture**

### ğŸŒŸ **MongoDB Atlas (Production Ready)**
**Why Atlas is Perfect for Your Flutter App:**

| Feature | Benefit | Impact |
|---------|---------|---------|
| ğŸš€ **Zero Setup** | No database management | Focus on app development |
| ğŸŒ **Global Clusters** | Deploy worldwide | Low latency for users |
| ğŸ”’ **Enterprise Security** | Built-in encryption | Secure user data |
| ğŸ“Š **Real-time Monitoring** | Performance insights | Optimize app performance |
| ğŸ’¾ **Automatic Backups** | Point-in-time recovery | Never lose data |
| ğŸ’° **Free Tier** | 512MB free forever | Perfect for development |

**Atlas Setup Guide**: See `MONGODB_ATLAS_SETUP.md` for detailed instructions.

### ğŸ“Š **Database Schema Design**

```javascript
// User Collection
{
  _id: ObjectId,
  email: "user@example.com",
  name: "John Doe",
  provider: "local|google",
  quota: {
    limit: 100,
    used: 25,
    resetDate: ISODate
  },
  avatar: "/uploads/avatars/user_123.jpg",
  isActive: true,
  createdAt: ISODate,
  lastLogin: ISODate
}

// AI Jobs Collection
{
  _id: ObjectId,
  userId: ObjectId,
  type: "chat|whisper|tts|vision|embedding",
  status: "pending|processing|completed|failed",
  input: { message: "Hello AI" },
  output: { response: "Hello! How can I help?" },
  tokensUsed: 150,
  processingTime: 1250,
  createdAt: ISODate
}

// Video Jobs Collection
{
  _id: ObjectId,
  userId: ObjectId,
  filename: "video_123.mp4",
  status: "uploaded|processing|completed|failed",
  metadata: {
    duration: 120.5,
    width: 1920,
    height: 1080,
    fps: 30
  },
  frames: [
    {
      timestamp: 1.0,
      filename: "frame_001.jpg",
      filePath: "/uploads/frames/frame_001.jpg"
    }
  ]
}
```

## ğŸ“± **Flutter Integration**

### ğŸ”§ **Complete Flutter Setup**

#### **Dependencies** (`pubspec.yaml`)
```yaml
dependencies:
  dio: ^5.3.2                    # HTTP client
  flutter_secure_storage: ^9.0.0 # Secure token storage
  image_picker: ^1.0.4           # Image/video picker
  file_picker: ^6.1.1            # File picker
  audioplayers: ^5.2.1           # Audio playback
  record: ^5.0.4                 # Audio recording
  video_player: ^2.8.1           # Video playback
  cached_network_image: ^3.3.0   # Image caching
  permission_handler: ^11.0.1    # Permissions
```

#### **API Client Setup**
```dart
// lib/services/api_client.dart
import 'package:dio/dio.dart';
import 'package:flutter_secure_storage/flutter_secure_storage.dart';

class ApiClient {
  static const String baseUrl = 'http://10.0.2.2:3000/api'; // Android emulator
  // static const String baseUrl = 'http://localhost:3000/api'; // iOS simulator
  // static const String baseUrl = 'https://your-api.com/api'; // Production
  
  static final Dio _dio = Dio(BaseOptions(
    baseUrl: baseUrl,
    connectTimeout: Duration(seconds: 30),
    receiveTimeout: Duration(seconds: 30),
  ));
  
  static const FlutterSecureStorage _storage = FlutterSecureStorage();
  
  static Future<void> initialize() async {
    // Auto-attach auth token
    _dio.interceptors.add(InterceptorsWrapper(
      onRequest: (options, handler) async {
        final token = await _storage.read(key: 'access_token');
        if (token != null) {
          options.headers['Authorization'] = 'Bearer $token';
        }
        handler.next(options);
      },
      onError: (error, handler) async {
        // Auto token refresh on 401
        if (error.response?.statusCode == 401) {
          final refreshed = await _refreshToken();
          if (refreshed) {
            // Retry original request
            final token = await _storage.read(key: 'access_token');
            error.requestOptions.headers['Authorization'] = 'Bearer $token';
            final response = await _dio.fetch(error.requestOptions);
            handler.resolve(response);
            return;
          }
        }
        handler.next(error);
      },
    ));
  }
}
```

#### **Authentication Service**
```dart
// lib/services/auth_service.dart
class AuthService {
  // Register new user
  static Future<AuthResult> register({
    required String email,
    required String password,
    required String name,
  }) async {
    try {
      final response = await ApiClient.dio.post('/auth/register', data: {
        'email': email,
        'password': password,
        'name': name,
      });
      
      if (response.data['success']) {
        final data = response.data['data'];
        await _storeTokens(data['accessToken'], data['refreshToken']);
        return AuthResult.success(User.fromJson(data['user']));
      }
      return AuthResult.error(response.data['message']);
    } catch (e) {
      return AuthResult.error('Registration failed: $e');
    }
  }
  
  // Login existing user
  static Future<AuthResult> login({
    required String email,
    required String password,
  }) async {
    try {
      final response = await ApiClient.dio.post('/auth/login', data: {
        'email': email,
        'password': password,
      });
      
      if (response.data['success']) {
        final data = response.data['data'];
        await _storeTokens(data['accessToken'], data['refreshToken']);
        return AuthResult.success(User.fromJson(data['user']));
      }
      return AuthResult.error(response.data['message']);
    } catch (e) {
      return AuthResult.error('Login failed: $e');
    }
  }
  
  // Store tokens securely
  static Future<void> _storeTokens(String accessToken, String refreshToken) async {
    await ApiClient.storage.write(key: 'access_token', value: accessToken);
    await ApiClient.storage.write(key: 'refresh_token', value: refreshToken);
  }
}

class AuthResult {
  final bool success;
  final User? user;
  final String? error;
  
  AuthResult.success(this.user) : success = true, error = null;
  AuthResult.error(this.error) : success = false, user = null;
}
```

#### **AI Services Integration**
```dart
// lib/services/ai_service.dart
class AIService {
  // ğŸ’¬ Chat with GPT-4
  static Future<ChatResponse> sendMessage({
    required String message,
    String? conversationId,
    String? model = 'gpt-4',
  }) async {
    final response = await ApiClient.dio.post('/ai/chat', data: {
      'message': message,
      'conversationId': conversationId,
      'model': model,
    });
    return ChatResponse.fromJson(response.data['data']);
  }
  
  // ğŸ¤ Speech to Text (Whisper)
  static Future<TranscriptionResponse> transcribeAudio(File audioFile) async {
    final formData = FormData.fromMap({
      'audio': await MultipartFile.fromFile(audioFile.path),
    });
    
    final response = await ApiClient.dio.post('/ai/speech-to-text', data: formData);
    return TranscriptionResponse.fromJson(response.data['data']);
  }
  
  // ğŸ”Š Text to Speech
  static Future<Uint8List> synthesizeSpeech({
    required String text,
    String voice = 'alloy',
  }) async {
    final response = await ApiClient.dio.post('/ai/text-to-speech',
      data: {'text': text, 'voice': voice},
      options: Options(responseType: ResponseType.bytes),
    );
    return response.data;
  }
  
  // ğŸ‘ï¸ Image Analysis (GPT-4 Vision)
  static Future<VisionResponse> analyzeImage({
    required File imageFile,
    String? prompt,
  }) async {
    final formData = FormData.fromMap({
      'image': await MultipartFile.fromFile(imageFile.path),
      if (prompt != null) 'prompt': prompt,
    });
    
    final response = await ApiClient.dio.post('/ai/analyze-image', data: formData);
    return VisionResponse.fromJson(response.data['data']);
  }
  
  // ğŸ§  Create Embeddings
  static Future<EmbeddingResponse> createEmbedding(String text) async {
    final response = await ApiClient.dio.post('/embeddings/create', data: {
      'text': text,
      'autoChunk': true,
    });
    return EmbeddingResponse.fromJson(response.data['data']);
  }
  
  // ğŸ” Semantic Search
  static Future<List<SearchResult>> searchSimilar({
    required String query,
    int limit = 10,
    double threshold = 0.7,
  }) async {
    final response = await ApiClient.dio.post('/embeddings/search', data: {
      'query': query,
      'limit': limit,
      'threshold': threshold,
    });
    
    final results = response.data['data']['results'] as List;
    return results.map((r) => SearchResult.fromJson(r)).toList();
  }
}
```

#### **Video Processing Service**
```dart
// lib/services/video_service.dart
class VideoService {
  // ğŸ“¤ Upload and Process Video
  static Future<VideoUploadResponse> uploadVideo({
    required File videoFile,
    bool extractFrames = true,
    double frameInterval = 1.0,
    int maxFrames = 100,
  }) async {
    final formData = FormData.fromMap({
      'video': await MultipartFile.fromFile(videoFile.path),
      'extractFrames': extractFrames,
      'frameInterval': frameInterval,
      'maxFrames': maxFrames,
    });
    
    final response = await ApiClient.dio.post('/video/upload', data: formData);
    return VideoUploadResponse.fromJson(response.data['data']);
  }
  
  // ğŸ“Š Get Processing Status
  static Future<VideoJob> getVideoJob(String jobId) async {
    final response = await ApiClient.dio.get('/video/jobs/$jobId');
    return VideoJob.fromJson(response.data['data']);
  }
  
  // ğŸ–¼ï¸ Get Extracted Frame
  static Future<Uint8List> getFrame(String jobId, int frameIndex) async {
    final response = await ApiClient.dio.get('/video/jobs/$jobId/frames/$frameIndex',
      options: Options(responseType: ResponseType.bytes),
    );
    return response.data;
  }
  
  // ğŸ–¼ï¸ Get Video Thumbnail
  static Future<Uint8List> getThumbnail(String jobId, {double timestamp = 1.0}) async {
    final response = await ApiClient.dio.get('/video/jobs/$jobId/thumbnail',
      queryParameters: {'timestamp': timestamp},
      options: Options(responseType: ResponseType.bytes),
    );
    return response.data;
  }
  
  // ğŸ“‹ List User Videos
  static Future<List<VideoJob>> getUserVideos({int page = 1, int limit = 20}) async {
    final response = await ApiClient.dio.get('/video/jobs',
      queryParameters: {'page': page, 'limit': limit},
    );
    
    final jobs = response.data['data'] as List;
    return jobs.map((job) => VideoJob.fromJson(job)).toList();
  }
}
```

**ğŸ“– Complete Flutter Integration Guide**: See `FLUTTER_INTEGRATION.md` for detailed examples, widgets, and best practices.

## ğŸ› ï¸ **API Reference**

### ğŸ“¡ **Complete Endpoint Documentation**

| Category | Endpoint | Method | Description | Auth Required |
|----------|----------|---------|-------------|---------------|
| **ğŸ” Authentication** |
| | `/api/auth/register` | POST | Register new user | âŒ |
| | `/api/auth/login` | POST | Login user | âŒ |
| | `/api/auth/refresh` | POST | Refresh access token | âŒ |
| | `/api/auth/logout` | POST | Logout user | âŒ |
| | `/api/auth/me` | GET | Get current user | âœ… |
| | `/api/auth/logout-all` | POST | Logout all devices | âœ… |
| | `/api/auth/sessions` | GET | List active sessions | âœ… |
| **ğŸ¤– AI Services** |
| | `/api/ai/chat` | POST | GPT-4 chat completion | âœ… |
| | `/api/ai/speech-to-text` | POST | Whisper transcription | âœ… |
| | `/api/ai/text-to-speech` | POST | Voice synthesis | âœ… |
| | `/api/ai/analyze-image` | POST | GPT-4 Vision analysis | âœ… |
| | `/api/ai/jobs` | GET | AI job history | âœ… |
| | `/api/ai/jobs/:id` | GET | Specific AI job details | âœ… |
| **ğŸ¥ Video Processing** |
| | `/api/video/upload` | POST | Upload & process video | âœ… |
| | `/api/video/jobs` | GET | List video jobs | âœ… |
| | `/api/video/jobs/:id` | GET | Video job details | âœ… |
| | `/api/video/jobs/:id/frames/:index` | GET | Get frame image | âœ… |
| | `/api/video/jobs/:id/thumbnail` | GET | Get video thumbnail | âœ… |
| | `/api/video/jobs/:id` | DELETE | Delete video job | âœ… |
| **ğŸ§  Embeddings** |
| | `/api/embeddings/create` | POST | Create text embedding | âœ… |
| | `/api/embeddings/search` | POST | Semantic search | âœ… |
| | `/api/embeddings` | GET | List user embeddings | âœ… |
| | `/api/embeddings/stats` | GET | Embedding statistics | âœ… |
| | `/api/embeddings/:id` | GET | Embedding details | âœ… |
| | `/api/embeddings/:id` | DELETE | Delete embedding | âœ… |
| | `/api/embeddings/bulk-delete` | POST | Delete multiple embeddings | âœ… |
| **ğŸ‘¤ User Management** |
| | `/api/user/profile` | GET | Get user profile | âœ… |
| | `/api/user/profile` | PUT | Update profile | âœ… |
| | `/api/user/avatar` | POST | Upload avatar | âœ… |
| | `/api/user/avatar` | DELETE | Delete avatar | âœ… |
| | `/api/user/quota` | GET | Quota information | âœ… |
| | `/api/user/usage-stats` | GET | Usage statistics | âœ… |
| | `/api/user/deactivate` | POST | Deactivate account | âœ… |

### ğŸ“‹ **Standard Response Format**

**âœ… Success Response:**
```json
{
  "success": true,
  "message": "Operation completed successfully",
  "data": {
    // Response data object
  },
  "meta": {
    "pagination": {
      "page": 1,
      "limit": 20,
      "total": 100,
      "pages": 5
    }
  }
}
```

**âŒ Error Response:**
```json
{
  "success": false,
  "message": "Descriptive error message",
  "error": "Detailed error information (development only)"
}
```

### ğŸ”’ **Authentication Examples**

**Register User:**
```bash
curl -X POST http://localhost:3000/api/auth/register \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "securePassword123",
    "name": "John Doe"
  }'
```

**Login User:**
```bash
curl -X POST http://localhost:3000/api/auth/login \
  -H "Content-Type: application/json" \
  -d '{
    "email": "user@example.com",
    "password": "securePassword123"
  }'
```

**Chat with AI:**
```bash
curl -X POST http://localhost:3000/api/ai/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_ACCESS_TOKEN" \
  -d '{
    "message": "Explain quantum computing in simple terms",
    "model": "gpt-4"
  }'
```

## âš¡ **Performance & Security**

### ğŸ›¡ï¸ **Security Features**

| Feature | Implementation | Benefit |
|---------|----------------|---------|
| **ğŸ” JWT Authentication** | Access + Refresh tokens | Secure, stateless auth |
| **ğŸš« Rate Limiting** | IP-based limits | Prevent API abuse |
| **ğŸ“Š Quota Management** | User-based limits | Control resource usage |
| **ğŸ”’ Input Validation** | Joi + Express Validator | Prevent injection attacks |
| **ğŸ›¡ï¸ Security Headers** | Helmet.js | XSS, CSRF protection |
| **ğŸŒ CORS Protection** | Configurable origins | Control access |
| **ğŸ“ Request Logging** | Winston logger | Audit trail |
| **ğŸ” File Validation** | Type & size checks | Prevent malicious uploads |

### ğŸš€ **Rate Limiting Configuration**

| Endpoint Category | Rate Limit | Window | Burst Allowed |
|-------------------|------------|---------|---------------|
| **General API** | 60 req/min | 1 minute | 20 requests |
| **Authentication** | 5 attempts | 15 minutes | 2 attempts |
| **AI Services** | 10 req/min | 1 minute | 5 requests |
| **Video Upload** | 3 uploads | 1 minute | 1 upload |
| **File Downloads** | 100 req/min | 1 minute | 50 requests |

### ğŸ’³ **Intelligent Quota System**

| Service | Quota Cost | Calculation | Example |
|---------|------------|-------------|---------|
| **ğŸ’¬ Chat** | 2 units | Per request | 1 chat = 2 units |
| **ğŸ¤ Speech-to-Text** | 1 unit | Per minute of audio | 3min audio = 3 units |
| **ğŸ”Š Text-to-Speech** | 1 unit | Per 1000 characters | 2000 chars = 2 units |
| **ğŸ‘ï¸ Vision** | 3 units | Per image analysis | 1 image = 3 units |
| **ğŸ¥ Video Processing** | 5 units | Per video | 1 video = 5 units |
| **ğŸ§  Embeddings** | 1 unit | Per 1000 tokens | 2000 tokens = 2 units |

**Default Quota**: 100 units/month (resets monthly)  
**Quota Warning**: Alert at 80% usage  
**Quota Reset**: Automatic monthly reset

### ğŸ“ **File Upload Specifications**

| File Type | Max Size | Duration Limit | Supported Formats | Processing |
|-----------|----------|----------------|-------------------|------------|
| **ğŸ–¼ï¸ Images** | 5MB | - | JPEG, PNG, GIF, WebP | Auto-resize, optimization |
| **ğŸµ Audio** | 25MB | 10 minutes | WAV, MP3, M4A, OGG | Whisper transcription |
| **ğŸ¥ Video** | 100MB | 5 minutes | MP4, AVI, MOV, WMV, WebM | Frame extraction, thumbnails |
| **ğŸ‘¤ Avatar** | 5MB | - | JPEG, PNG, GIF, WebP | Auto-crop to 200x200 |

**Upload Features:**
- âœ… **Real-time validation** - Instant feedback on file issues
- âœ… **Progress tracking** - Upload progress indicators
- âœ… **Auto-optimization** - Automatic image compression
- âœ… **Virus scanning** - File safety validation
- âœ… **CDN integration** - Fast global file delivery

## ğŸš€ **Deployment & Production**

### ğŸŒ **Production Deployment Options**

#### **ğŸ”¥ Quick Deploy (5 minutes)**
```bash
# 1. Setup MongoDB Atlas (free tier)
# 2. Configure environment variables
# 3. Deploy with Docker
docker-compose -f docker-compose.atlas.yml up -d

# 4. Setup SSL (Let's Encrypt)
certbot --nginx -d your-domain.com

# 5. Configure monitoring
docker-compose logs -f app
```

#### **â˜ï¸ Cloud Platform Deployment**

**AWS EC2:**
```bash
# Launch t3.medium instance (2 vCPU, 4GB RAM)
# Install Docker & Docker Compose
# Clone repository and configure .env
# Start services with docker-compose
```

**Google Cloud Platform:**
```bash
# Deploy to Compute Engine or Cloud Run
gcloud run deploy multimodal-ai-assistant \
  --image gcr.io/PROJECT_ID/multimodal-ai-assistant \
  --platform managed \
  --memory 2Gi
```

**DigitalOcean:**
```bash
# Create 4GB RAM droplet
# Follow standard Docker deployment
# Configure domain and SSL
```

### ğŸ“Š **Monitoring & Analytics**

**Built-in Monitoring:**
- âœ… **Health Checks** - `/health` endpoint with detailed status
- âœ… **Request Logging** - Winston with daily rotation
- âœ… **Error Tracking** - Comprehensive error logging
- âœ… **Performance Metrics** - Response time tracking
- âœ… **Usage Analytics** - User activity and API usage
- âœ… **Database Monitoring** - MongoDB Atlas dashboard

**Production Monitoring Stack:**
```yaml
# docker-compose.monitoring.yml
services:
  prometheus:    # Metrics collection
  grafana:       # Visualization dashboard
  alertmanager:  # Alert notifications
  node-exporter: # System metrics
```

### ğŸ”§ **Development Environment**

**Development Scripts:**
```bash
npm run dev      # Start with hot reload (nodemon)
npm run lint     # ESLint code checking
npm run test     # Run test suite
npm start        # Production server
npm run build    # Build for production
```

**Development Tools:**
- **ğŸ”„ Hot Reload** - Nodemon for instant code changes
- **ğŸ§ª Testing** - Jest test framework
- **ğŸ“ Code Quality** - ESLint + Prettier
- **ğŸ“š API Docs** - Auto-generated Swagger documentation
- **ğŸ› Debugging** - VS Code debug configuration
- **ğŸ“Š Logging** - Detailed development logs

### ğŸ—ï¸ **Project Architecture**

```
multimodal-ai-assistant/
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ“ config/          # Configuration management
â”‚   â”‚   â”œâ”€â”€ index.js        # Main config loader
â”‚   â”‚   â”œâ”€â”€ database.js     # MongoDB connection
â”‚   â”‚   â”œâ”€â”€ logger.js       # Winston logging setup
â”‚   â”‚   â””â”€â”€ swagger.js      # API documentation
â”‚   â”œâ”€â”€ ğŸ“ controllers/     # Request handlers
â”‚   â”‚   â”œâ”€â”€ authController.js
â”‚   â”‚   â”œâ”€â”€ aiController.js
â”‚   â”‚   â”œâ”€â”€ videoController.js
â”‚   â”‚   â”œâ”€â”€ embeddingsController.js
â”‚   â”‚   â””â”€â”€ userController.js
â”‚   â”œâ”€â”€ ğŸ“ middleware/      # Express middleware
â”‚   â”‚   â”œâ”€â”€ auth.js         # JWT authentication
â”‚   â”‚   â”œâ”€â”€ rateLimiter.js  # Rate limiting
â”‚   â”‚   â”œâ”€â”€ quota.js        # Usage quotas
â”‚   â”‚   â”œâ”€â”€ validator.js    # Input validation
â”‚   â”‚   â””â”€â”€ errorHandler.js # Error handling
â”‚   â”œâ”€â”€ ğŸ“ models/          # MongoDB schemas
â”‚   â”‚   â”œâ”€â”€ User.js         # User model
â”‚   â”‚   â”œâ”€â”€ AIJob.js        # AI jobs tracking
â”‚   â”‚   â”œâ”€â”€ VideoJob.js     # Video processing
â”‚   â”‚   â”œâ”€â”€ Embedding.js    # Text embeddings
â”‚   â”‚   â””â”€â”€ RefreshToken.js # Token management
â”‚   â”œâ”€â”€ ğŸ“ routes/          # API route definitions
â”‚   â”‚   â”œâ”€â”€ auth.js         # Authentication routes
â”‚   â”‚   â”œâ”€â”€ ai.js           # AI service routes
â”‚   â”‚   â”œâ”€â”€ video.js        # Video processing routes
â”‚   â”‚   â”œâ”€â”€ embeddings.js   # Embedding routes
â”‚   â”‚   â””â”€â”€ user.js         # User management routes
â”‚   â”œâ”€â”€ ğŸ“ services/        # Business logic
â”‚   â”‚   â”œâ”€â”€ authService.js  # Authentication logic
â”‚   â”‚   â”œâ”€â”€ openaiService.js # OpenAI API integration
â”‚   â”‚   â”œâ”€â”€ videoService.js # Video processing
â”‚   â”‚   â””â”€â”€ embeddingService.js # Embedding operations
â”‚   â”œâ”€â”€ ğŸ“ utils/           # Utility functions
â”‚   â”‚   â””â”€â”€ index.js        # Helper functions
â”‚   â””â”€â”€ server.js           # Main application entry
â”œâ”€â”€ ğŸ“ uploads/             # File storage
â”‚   â”œâ”€â”€ videos/             # Uploaded videos
â”‚   â”œâ”€â”€ frames/             # Extracted frames
â”‚   â””â”€â”€ avatars/            # User avatars
â”œâ”€â”€ ğŸ“ logs/                # Application logs
â”œâ”€â”€ ğŸ“„ docker-compose.yml   # Local development
â”œâ”€â”€ ğŸ“„ docker-compose.atlas.yml # MongoDB Atlas
â”œâ”€â”€ ğŸ“„ Dockerfile           # Container definition
â”œâ”€â”€ ğŸ“„ .env.example         # Environment template
â””â”€â”€ ğŸ“š Documentation/
    â”œâ”€â”€ MONGODB_ATLAS_SETUP.md
    â”œâ”€â”€ FLUTTER_INTEGRATION.md
    â”œâ”€â”€ DEPLOYMENT.md
    â””â”€â”€ QUICK_START_ATLAS.md
```

## ğŸ¤ **Contributing & Support**

### ğŸ› ï¸ **Contributing Guidelines**

1. **ğŸ´ Fork the Repository**
   ```bash
   git clone https://github.com/your-username/multimodal-ai-assistant.git
   cd multimodal-ai-assistant
   ```

2. **ğŸŒ¿ Create Feature Branch**
   ```bash
   git checkout -b feature/amazing-new-feature
   ```

3. **ğŸ’» Make Your Changes**
   - Follow existing code style
   - Add tests for new features
   - Update documentation
   - Ensure all tests pass

4. **ğŸ“ Commit Changes**
   ```bash
   git commit -m "feat: add amazing new feature"
   ```

5. **ğŸš€ Submit Pull Request**
   - Describe your changes
   - Link related issues
   - Request review

### ğŸ“š **Documentation Resources**

| Document | Description | Use Case |
|----------|-------------|----------|
| **ğŸ“– README.md** | Main documentation | Overview and setup |
| **ğŸš€ QUICK_START_ATLAS.md** | 5-minute setup guide | Fast deployment |
| **ğŸ—„ï¸ MONGODB_ATLAS_SETUP.md** | Database setup | MongoDB Atlas configuration |
| **ğŸ“± FLUTTER_INTEGRATION.md** | Flutter client code | Mobile app development |
| **ğŸŒ DEPLOYMENT.md** | Production deployment | Server deployment |
| **ğŸ“¡ API Documentation** | Interactive API docs | Available at `/api-docs` |

### ğŸ†˜ **Getting Help**

**ğŸ› Found a Bug?**
- Check existing [GitHub Issues](https://github.com/your-repo/issues)
- Create detailed bug report with:
  - Steps to reproduce
  - Expected vs actual behavior
  - Environment details
  - Error logs

**ğŸ’¡ Feature Request?**
- Open a [Feature Request](https://github.com/your-repo/issues/new)
- Describe the use case
- Explain expected behavior
- Consider implementation approach

**â“ Need Support?**
- ğŸ“š Check documentation first
- ğŸ” Search existing issues
- ğŸ’¬ Join our [Discord Community](https://discord.gg/your-server)
- ğŸ“§ Email: support@your-domain.com

### ğŸ† **Contributors**

Thanks to all contributors who have helped make this project better!

<!-- Add contributor avatars here -->

### ğŸ“„ **License**

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 Multimodal AI Assistant

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

---

## ğŸŒŸ **Why Choose This Backend?**

### âœ… **Production Ready**
- Enterprise-grade security and authentication
- Comprehensive error handling and logging
- Docker containerization for easy deployment
- MongoDB Atlas integration for scalability

### âœ… **Flutter Optimized**
- Mobile-first API design
- Efficient file upload handling
- Proper error responses for mobile apps
- Complete Flutter integration examples

### âœ… **AI-Powered**
- Latest OpenAI GPT-4 integration
- Multi-modal AI capabilities (text, speech, vision)
- Semantic search with embeddings
- Professional video processing pipeline

### âœ… **Developer Friendly**
- Comprehensive documentation
- Interactive API documentation
- Easy local development setup
- Extensive Flutter code examples

### âœ… **Scalable Architecture**
- Microservices-ready design
- Rate limiting and quota management
- MongoDB Atlas for global scaling
- Cloud deployment ready

---

**ğŸš€ Ready to build the next generation of AI-powered mobile apps? Get started now!**

```bash
# Quick start in 5 minutes
git clone https://github.com/your-repo/multimodal-ai-assistant.git
cd multimodal-ai-assistant
cp .env.example .env
# Add your MongoDB Atlas URI and OpenAI API key
docker-compose -f docker-compose.atlas.yml up -d
```

**ğŸ“± Start building your Flutter app with our complete integration guide!**

